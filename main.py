from fastapi import FastAPI, APIRouter, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.exceptions import RequestValidationError
from pydantic import BaseModel, Field, ValidationError
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI
import os
import logging
from config import settings

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# éªŒè¯é…ç½®
if not settings.validate():
    logger.error("âŒ é…ç½®éªŒè¯å¤±è´¥ï¼")
    if not settings.openai_api_key:
        logger.error("åŸå› : OPENAI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
    elif settings.openai_api_key == "your-openai-api-key-here":
        logger.error("åŸå› : OPENAI_API_KEY ä»ä¸ºé»˜è®¤å€¼ï¼Œè¯·è®¾ç½®çœŸå®çš„ API Key")
    elif not settings.openai_api_key.startswith(('sk-', 'sk_')):
        logger.error("åŸå› : OPENAI_API_KEY æ ¼å¼æ— æ•ˆï¼Œåº”ä»¥ 'sk-' å¼€å¤´")
    logger.error("è¯·æ£€æŸ¥ .env æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡é…ç½®")
else:
    logger.info(f"âœ… é…ç½®éªŒè¯é€šè¿‡ (æ¨¡å‹: {settings.default_model})")

app = FastAPI(
    title="PPTist AI Backend",
    description="AI-powered PPT generation backend using LangChain and FastAPI",
    version="0.1.0"
)

# é…ç½® CORS å…è®¸çš„æº
allowed_origins = [
    "http://localhost:3000",  # React å¼€å‘æœåŠ¡å™¨
    "http://localhost:5173",  # Vite å¼€å‘æœåŠ¡å™¨
    "http://127.0.0.1:3000",
    "http://127.0.0.1:5173",
    "http://localhost:8080",  # Vue å¼€å‘æœåŠ¡å™¨
    "http://127.0.0.1:8080",
]

# å¦‚æœæ˜¯è°ƒè¯•æ¨¡å¼ï¼Œå…è®¸æ‰€æœ‰æºï¼ˆå¼€å‘ç¯å¢ƒï¼‰
if settings.debug:
    allowed_origins = ["*"]
    logger.info("ğŸŒ CORS: è°ƒè¯•æ¨¡å¼ - å…è®¸æ‰€æœ‰æºè®¿é—®")
else:
    logger.info(f"ğŸŒ CORS: ç”Ÿäº§æ¨¡å¼ - å…è®¸çš„æº: {allowed_origins}")

# æ·»åŠ  CORS ä¸­é—´ä»¶é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=allowed_origins,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

# æ·»åŠ è¯·æ±‚éªŒè¯é”™è¯¯å¤„ç†å™¨
@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """å¤„ç†è¯·æ±‚éªŒè¯é”™è¯¯ï¼Œæä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯"""
    logger.error(f"ğŸš« è¯·æ±‚éªŒè¯å¤±è´¥: {request.method} {request.url}")
    logger.error(f"ğŸš« é”™è¯¯è¯¦æƒ…: {exc.errors()}")
    
    # æå–è¯·æ±‚ä½“ä¿¡æ¯
    try:
        body = await request.body()
        if body:
            logger.error(f"ğŸš« è¯·æ±‚ä½“: {body.decode('utf-8')}")
    except Exception:
        pass
    
    return JSONResponse(
        status_code=422,
        content={
            "detail": exc.errors(),
            "message": "è¯·æ±‚å‚æ•°éªŒè¯å¤±è´¥",
            "help": {
                "/tools/aippt_outline": "éœ€è¦å‚æ•°: model, language, content",
                "/tools/aippt": "éœ€è¦å‚æ•°: model, language, content"
            }
        }
    )

router = APIRouter()

# PPTå¤§çº²ç”Ÿæˆæ¨¡æ¿
outline_template = """ä½ æ˜¯ç”¨æˆ·çš„PPTå¤§çº²ç”ŸæˆåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ä¸‹åˆ—ä¸»é¢˜ç”Ÿæˆç« èŠ‚ç»“æ„ã€‚

æ³¨æ„äº‹é¡¹ï¼š
- å†…å®¹å’ŒèŠ‚çš„æ•°é‡å¯ä»¥æ ¹æ®ä¸»é¢˜çµæ´»è°ƒæ•´
- ä¸è¦æ·»åŠ ä»»ä½•æ³¨é‡Šæˆ–è§£é‡Šè¯´æ˜

è¾“å‡ºæ ¼å¼ä¸ºï¼š
# PPTæ ‡é¢˜ï¼ˆåªæœ‰ä¸€ä¸ªï¼‰
## ç« çš„åå­—
### èŠ‚çš„åå­—
- å†…å®¹1
- å†…å®¹2
- å†…å®¹3
### èŠ‚çš„åå­—
- xxxxx
- xxxxx
- xxxxx
### èŠ‚çš„åå­—
- xxxxx
- xxxxx
- xxxxx
- xxxxx

è¿™æ˜¯ç”Ÿæˆè¦æ±‚ï¼š{content}
è¿™æ˜¯ç”Ÿæˆçš„è¯­è¨€è¦æ±‚ï¼š{language}
"""

outline_prompt = PromptTemplate.from_template(outline_template)

# PPTå†…å®¹ç”Ÿæˆæ¨¡æ¿
ppt_content_template = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„PPTå†…å®¹ç”ŸæˆåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç»™å®šçš„å¤§çº²å†…å®¹ï¼Œç”Ÿæˆå®Œæ•´çš„PPTé¡µé¢å†…å®¹ç»“æ„ã€‚

é¡µé¢ç±»å‹åŒ…æ‹¬ï¼š
- å°é¢é¡µï¼š"cover"
- ç›®å½•é¡µï¼š"contents"
- å†…å®¹é¡µï¼š"content"
- è¿‡æ¸¡é¡µï¼š"transition"
- ç»“æŸé¡µï¼š"end"

è¾“å‡ºæ ¼å¼è¦æ±‚å¦‚ä¸‹ï¼š
- æ¯ä¸€é¡µä¸ºä¸€ä¸ªç‹¬ç«‹ JSON å¯¹è±¡
- æ¯ä¸ª JSON å¯¹è±¡å†™åœ¨**åŒä¸€è¡Œ**
- é¡µé¢ä¹‹é—´ç”¨ä¸¤ä¸ªæ¢è¡Œç¬¦åˆ†éš”
- ä¸è¦æ·»åŠ ä»»ä½•æ³¨é‡Šæˆ–è§£é‡Šè¯´æ˜

æ³¨æ„äº‹é¡¹ï¼š
- ç›®å½•é¡µçš„itemså¯ä»¥2~6ä¸ªï¼Œæœ€å¤š10ä¸ª
- å†…å®¹é¡µçš„itemsåªèƒ½æœ‰2~4ä¸ª

ç¤ºä¾‹æ ¼å¼ï¼ˆæ³¨æ„æ¯ä¸ª JSON å ä¸€è¡Œï¼‰ï¼š

{{"type": "cover", "data": {{ "title": "æ¥å£ç›¸å…³å†…å®¹ä»‹ç»", "text": "äº†è§£æ¥å£å®šä¹‰ã€è®¾è®¡ä¸å®ç°è¦ç‚¹" }}}}

{{"type": "contents", "data": {{ "items": ["æ¥å£å®šä¹‰æ¦‚è¿°", "æ¥å£åˆ†ç±»è¯¦æƒ…", "æ¥å£è®¾è®¡åŸåˆ™"] }}}}

{{"type": "transition", "data": {{ "title": "æ¥å£å®šä¹‰", "text": "å¼€å§‹ä»‹ç»æ¥å£çš„åŸºæœ¬å«ä¹‰" }}}}

{{"type": "content", "data": {{ "title": "æ¥å£å®šä¹‰", "items": [ {{ "title": "åŸºæœ¬æ¦‚å¿µ", "text": "æ¥å£æ˜¯ç³»ç»Ÿä¸­æ¨¡å—é€šä¿¡çš„åè®®" }}, {{ "title": "ä½œç”¨", "text": "ä¿ƒè¿›æ¨¡å—è§£è€¦ï¼Œæé«˜ç³»ç»Ÿçµæ´»æ€§" }} ] }}}}

{{"type": "end"}}


è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆ PPT å†…å®¹ï¼š

è¯­è¨€ï¼š{language}
å¤§çº²å†…å®¹ï¼š{content}
"""

ppt_content_prompt = PromptTemplate.from_template(ppt_content_template)


def build_outline_chain(model_name: str = None):
    """æ„å»ºPPTå¤§çº²ç”Ÿæˆé“¾"""
    if not settings.validate():
        raise HTTPException(status_code=500, detail="OpenAI API Key æœªé…ç½®")
    
    model_config = settings.get_model_config(model_name)
    llm = ChatOpenAI(
        temperature=model_config["temperature"],
        model=model_config["model"],
        openai_api_key=model_config["openai_api_key"],
        openai_api_base=model_config["openai_api_base"]
    )
    return outline_prompt | llm | StrOutputParser()


def build_ppt_content_chain(model_name: str = None):
    """æ„å»ºPPTå†…å®¹ç”Ÿæˆé“¾"""
    if not settings.validate():
        raise HTTPException(status_code=500, detail="OpenAI API Key æœªé…ç½®")
    
    model_config = settings.get_model_config(model_name)
    llm = ChatOpenAI(
        temperature=model_config["temperature"],
        model=model_config["model"],
        openai_api_key=model_config["openai_api_key"],
        openai_api_base=model_config["openai_api_base"]
    )
    return ppt_content_prompt | llm | StrOutputParser()


# è¯·æ±‚æ¨¡å‹å®šä¹‰
class PPTOutlineRequest(BaseModel):
    model: str = Field('gpt-4o-mini', description="ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼Œä¾‹å¦‚ gpt-4o æˆ– gpt-4o-mini")
    language: str = Field(..., description="ç”Ÿæˆå†…å®¹çš„è¯­è¨€ï¼Œä¾‹å¦‚ ä¸­æ–‡ã€English")
    content: str = Field(..., max_length=50, description="ç”Ÿæˆçš„è¦æ±‚ï¼Œä¸è¶…è¿‡50å­—")
    stream: bool = True


class PPTContentRequest(BaseModel):
    model: str = Field('gpt-4o-mini', description="ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼Œä¾‹å¦‚ gpt-4o æˆ– gpt-4o-mini")
    language: str = Field(..., description="ç”Ÿæˆå†…å®¹çš„è¯­è¨€ï¼Œä¾‹å¦‚ ä¸­æ–‡ã€English")
    content: str = Field(..., description="PPTå¤§çº²å†…å®¹")
    stream: bool = True


# è·¯ç”±å®ç°
@router.post("/tools/aippt_outline")
async def generate_ppt_outline_stream(request: PPTOutlineRequest):
    """ç”ŸæˆPPTå¤§çº²ï¼ˆæµå¼è¿”å›ï¼‰"""
    logger.info(f"ğŸ“ æ”¶åˆ°å¤§çº²ç”Ÿæˆè¯·æ±‚: æ¨¡å‹={request.model}, è¯­è¨€={request.language}, è¦æ±‚={request.content}")
    
    try:
        chain = build_outline_chain(request.model)
    except HTTPException as e:
        logger.error(f"æ„å»ºå¤§çº²ç”Ÿæˆé“¾å¤±è´¥: {e.detail}")
        raise e
    except Exception as e:
        logger.error(f"æ„å»ºå¤§çº²ç”Ÿæˆé“¾å¼‚å¸¸: {str(e)}")
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯")

    async def token_stream():
        try:
            logger.info("å¼€å§‹ç”ŸæˆPPTå¤§çº²...")
            async for chunk in chain.astream({
                "content": request.content,
                "language": request.language
            }):
                yield chunk
            logger.info("PPTå¤§çº²ç”Ÿæˆå®Œæˆ")
        except Exception as e:
            error_msg = f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"
            logger.error(error_msg)
            yield f"é”™è¯¯: {error_msg}"

    return StreamingResponse(token_stream(), media_type="text/event-stream")


@router.post("/tools/aippt")
async def generate_ppt_content_stream(request: PPTContentRequest):
    """ç”ŸæˆPPTå†…å®¹ï¼ˆæµå¼è¿”å›ï¼‰"""
    logger.info(f"ğŸ“„ æ”¶åˆ°å†…å®¹ç”Ÿæˆè¯·æ±‚: æ¨¡å‹={request.model}, è¯­è¨€={request.language}")
    logger.info(f"ğŸ“„ å¤§çº²å†…å®¹é•¿åº¦: {len(request.content)} å­—ç¬¦")
    
    try:
        chain = build_ppt_content_chain(request.model)
    except HTTPException as e:
        logger.error(f"æ„å»ºå†…å®¹ç”Ÿæˆé“¾å¤±è´¥: {e.detail}")
        raise e
    except Exception as e:
        logger.error(f"æ„å»ºå†…å®¹ç”Ÿæˆé“¾å¼‚å¸¸: {str(e)}")
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯")
    
    async def page_stream():
        buffer = ""
        page_count = 0
        try:
            logger.info("å¼€å§‹ç”ŸæˆPPTå†…å®¹...")
            async for chunk in chain.astream({
                "language": request.language,
                "content": request.content
            }):
                buffer += chunk
                # æ£€æŸ¥ç¼“å†²åŒºä¸­æ˜¯å¦åŒ…å«å®Œæ•´çš„é¡µé¢åˆ†éš”ç¬¦ "\n\n"
                while "\n\n" in buffer:
                    page_content, separator, rest_of_buffer = buffer.partition("\n\n")
                    if page_content.strip():  # ç¡®ä¿ä¸æ˜¯ç”±å¤šä¸ªæ¢è¡Œç¬¦äº§ç”Ÿçš„ç©ºå†…å®¹
                        page_count += 1
                        logger.debug(f"ç”Ÿæˆç¬¬ {page_count} é¡µå†…å®¹")
                        yield page_content + separator  # ä¿ç•™åˆ†éš”ç¬¦
                    buffer = rest_of_buffer
            
            # å¤„ç†æµç»“æŸåç¼“å†²åŒºä¸­å‰©ä½™çš„æœ€åä¸€éƒ¨åˆ†å†…å®¹ï¼ˆå¦‚æœLLMè¾“å‡ºæœ«å°¾æ²¡æœ‰ \n\nï¼‰
            if buffer.strip():
                page_count += 1
                logger.debug(f"ç”Ÿæˆç¬¬ {page_count} é¡µå†…å®¹ï¼ˆæœ€åä¸€é¡µï¼‰")
                yield buffer.strip()
            
            logger.info(f"PPTå†…å®¹ç”Ÿæˆå®Œæˆï¼Œæ€»å…±ç”Ÿæˆ {page_count} é¡µ")
        except Exception as e:
            error_msg = f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"
            logger.error(error_msg)
            yield f'{{"error": "{error_msg}"}}'

    return StreamingResponse(page_stream(), media_type="text/event-stream")


# æ·»åŠ å¥åº·æ£€æŸ¥ç«¯ç‚¹
@router.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {"status": "healthy", "message": "PPTist AI Backend is running"}


# æ³¨å†Œè·¯ç”±
app.include_router(router)


# æ ¹è·¯å¾„
@app.get("/")
async def root():
    return {
        "message": "Welcome to PPTist AI Backend",
        "version": "0.1.0",
        "endpoints": {
            "outline": "/tools/aippt_outline",
            "content": "/tools/aippt",
            "health": "/health",
            "docs": "/docs"
        }
    }


if __name__ == "__main__":
    import uvicorn
    
    if not settings.validate():
        logger.error("âŒ å¯åŠ¨å¤±è´¥: OpenAI API Key æœªé…ç½®æˆ–æ— æ•ˆ")
        logger.error("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡æˆ–åˆ›å»º .env æ–‡ä»¶")
        logger.error("å¯ä»¥å¤åˆ¶ .env.example ä¸º .env å¹¶ä¿®æ”¹å…¶ä¸­çš„ API Key")
        exit(1)
    
    logger.info(f"ğŸš€ å¯åŠ¨ PPTist AI Backend...")
    logger.info(f"ğŸ“¡ æœåŠ¡å™¨åœ°å€: http://{settings.host}:{settings.port}")
    logger.info(f"ğŸ“š API æ–‡æ¡£: http://{settings.host}:{settings.port}/docs")
    
    try:
        uvicorn.run(
            "main:app",  # ä½¿ç”¨å­—ç¬¦ä¸²å¯¼å…¥è·¯å¾„ä»¥æ”¯æŒ reload åŠŸèƒ½
            host=settings.host,
            port=settings.port,
            reload=settings.debug
        )
    except Exception as e:
        logger.error(f"âŒ å¯åŠ¨å¤±è´¥: {str(e)}")
        logger.error("è¯·æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨æˆ–å…¶ä»–å¯åŠ¨é—®é¢˜")
        raise
