from fastapi import FastAPI, APIRouter, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.exceptions import RequestValidationError
from pydantic import BaseModel, Field
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI
import os
import json
import logging
from config import settings

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# éªŒè¯é…ç½®
if not settings.validate():
    logger.error("âŒ é…ç½®éªŒè¯å¤±è´¥ï¼")
    if not settings.openai_api_key:
        logger.error("åŸå› : OPENAI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
    elif settings.openai_api_key == "your-openai-api-key-here":
        logger.error("åŸå› : OPENAI_API_KEY ä»ä¸ºé»˜è®¤å€¼ï¼Œè¯·è®¾ç½®çœŸå®çš„ API Key")
    logger.error("è¯·æ£€æŸ¥ .env æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡é…ç½®")
else:
    logger.info(f"âœ… é…ç½®éªŒè¯é€šè¿‡ (æ¨¡å‹: {settings.default_model})")

app = FastAPI(
    title="PPTist AI Backend",
    description="AI-powered PPT generation backend using LangChain and FastAPI",
    version="0.1.0"
)

# é…ç½® CORS å…è®¸çš„æº
allowed_origins = [
    "http://localhost:3000",  # React å¼€å‘æœåŠ¡å™¨
    "http://localhost:5173",  # Vite å¼€å‘æœåŠ¡å™¨
    "http://127.0.0.1:3000",
    "http://127.0.0.1:5173",
    "http://localhost:8080",  # Vue å¼€å‘æœåŠ¡å™¨
    "http://127.0.0.1:8080",
    
]

# å¦‚æœæ˜¯è°ƒè¯•æ¨¡å¼ï¼Œå…è®¸æ‰€æœ‰æºï¼ˆå¼€å‘ç¯å¢ƒï¼‰
if settings.debug:
    allowed_origins = ["*"]
    logger.info("ğŸŒ CORS: è°ƒè¯•æ¨¡å¼ - å…è®¸æ‰€æœ‰æºè®¿é—®")
else:
    logger.info(f"ğŸŒ CORS: ç”Ÿäº§æ¨¡å¼ - å…è®¸çš„æº: {allowed_origins}")

# æ·»åŠ  CORS ä¸­é—´ä»¶é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=allowed_origins,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

# æ·»åŠ è¯·æ±‚éªŒè¯é”™è¯¯å¤„ç†å™¨
@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """å¤„ç†è¯·æ±‚éªŒè¯é”™è¯¯ï¼Œæä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯"""
    logger.error(f"ğŸš« è¯·æ±‚éªŒè¯å¤±è´¥: {request.method} {request.url}")
    logger.error(f"ğŸš« é”™è¯¯è¯¦æƒ…: {exc.errors()}")
    
    # æå–è¯·æ±‚ä½“ä¿¡æ¯
    try:
        body = await request.body()
        if body:
            logger.error(f"ğŸš« è¯·æ±‚ä½“: {body.decode('utf-8')}")
    except Exception:
        pass
    
    return JSONResponse(
        status_code=422,
        content={
            "detail": exc.errors(),
            "message": "è¯·æ±‚å‚æ•°éªŒè¯å¤±è´¥",
            "help": {
                "/tools/aippt_outline": "éœ€è¦å‚æ•°: model, language, content",
                "/tools/aippt": "éœ€è¦å‚æ•°: model, language, content"
            }
        }
    )

router = APIRouter()

# PPTå¤§çº²ç”Ÿæˆæ¨¡æ¿
outline_template = """ä½ æ˜¯ç”¨æˆ·çš„PPTå¤§çº²ç”ŸæˆåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ä¸‹åˆ—ä¸»é¢˜ç”Ÿæˆç« èŠ‚ç»“æ„ã€‚

æ³¨æ„äº‹é¡¹ï¼š
- èŠ‚å¯ä»¥æœ‰2~6ä¸ªï¼Œæœ€å¤š10ä¸ª
- æ¯ä¸ªèŠ‚å†…å®¹æ•°é‡åªèƒ½æœ‰1~10ä¸ªï¼Œå°½é‡ä¿è¯æ¯ä¸ªèŠ‚çš„å†…å®¹æ•°ä¸åŒ
- å†…å®¹å’ŒèŠ‚çš„æ•°é‡å¯ä»¥æ ¹æ®ä¸»é¢˜çµæ´»è°ƒæ•´
- ä¸è¦æ·»åŠ ä»»ä½•æ³¨é‡Šæˆ–è§£é‡Šè¯´æ˜

è¾“å‡ºæ ¼å¼ä¸ºï¼š
# PPTæ ‡é¢˜ï¼ˆåªæœ‰ä¸€ä¸ªï¼‰
## ç« çš„åå­—
### èŠ‚çš„åå­—
- å†…å®¹1
- å†…å®¹2
### èŠ‚çš„åå­—
- xxxxx
- xxxxx
- xxxxx
### èŠ‚çš„åå­—
- xxxxx
- xxxxx
- xxxxx
- xxxxx

è¿™æ˜¯ç”Ÿæˆè¦æ±‚ï¼š{content}
è¿™æ˜¯ç”Ÿæˆçš„è¯­è¨€è¦æ±‚ï¼š{language}
"""

outline_prompt = PromptTemplate.from_template(outline_template)

# PPTå°é¢é¡µå’Œç›®å½•é¡µç”Ÿæˆæ¨¡æ¿
cover_contents_template = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„PPTå†…å®¹ç”ŸæˆåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç»™å®šçš„å¤§çº²å†…å®¹ï¼Œç”Ÿæˆå°é¢é¡µå’Œç›®å½•é¡µçš„JSONå†…å®¹ã€‚

è¾“å‡ºæ ¼å¼è¦æ±‚å¦‚ä¸‹ï¼š
- æ¯ä¸€é¡µä¸ºä¸€ä¸ªç‹¬ç«‹ JSON å¯¹è±¡
- æ¯ä¸ª JSON å¯¹è±¡å†™åœ¨**åŒä¸€è¡Œ**
- é¡µé¢ä¹‹é—´ç”¨ä¸¤ä¸ªæ¢è¡Œç¬¦åˆ†éš”
- ä¸è¦æ·»åŠ ä»»ä½•æ³¨é‡Šæˆ–è§£é‡Šè¯´æ˜

æ³¨æ„äº‹é¡¹ï¼š
- åªç”Ÿæˆå°é¢é¡µ("cover")å’Œç›®å½•é¡µ("contents")
- æ¯ä¸ªtextçš„ä»‹ç»å†…å®¹å¯ä»¥å°½é‡ä¸°å¯Œï¼Œä½†æ˜¯ä¸åº”è¯¥è¶…è¿‡100å­—

ç¤ºä¾‹æ ¼å¼ï¼ˆæ³¨æ„æ¯ä¸ª JSON å ä¸€è¡Œï¼‰ï¼š

{{"type": "cover", "data": {{ "title": "æ¥å£ç›¸å…³å†…å®¹ä»‹ç»", "text": "äº†è§£æ¥å£å®šä¹‰ã€è®¾è®¡ä¸å®ç°è¦ç‚¹" }}}}

{{"type": "contents", "data": {{ "items": ["æ¥å£å®šä¹‰æ¦‚è¿°", "æ¥å£åˆ†ç±»è¯¦æƒ…", "æ¥å£è®¾è®¡åŸåˆ™"] }}}}

è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆå°é¢é¡µå’Œç›®å½•é¡µï¼š

è¯­è¨€ï¼š{language}
å¤§çº²å†…å®¹ï¼š{content}
"""

cover_contents_prompt = PromptTemplate.from_template(cover_contents_template)

# PPTç« èŠ‚å†…å®¹ç”Ÿæˆæ¨¡æ¿
section_content_template = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„PPTå†…å®¹ç”ŸæˆåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç»™å®šçš„ç« èŠ‚ä¿¡æ¯ï¼Œç”Ÿæˆè¯¥ç« èŠ‚çš„è¿‡æ¸¡é¡µå’Œå†…å®¹é¡µçš„JSONå†…å®¹ã€‚

è¾“å‡ºæ ¼å¼è¦æ±‚å¦‚ä¸‹ï¼š
- æ¯ä¸€é¡µä¸ºä¸€ä¸ªç‹¬ç«‹ JSON å¯¹è±¡
- æ¯ä¸ª JSON å¯¹è±¡å†™åœ¨**åŒä¸€è¡Œ**
- é¡µé¢ä¹‹é—´ç”¨ä¸¤ä¸ªæ¢è¡Œç¬¦åˆ†éš”
- ä¸è¦æ·»åŠ ä»»ä½•æ³¨é‡Šæˆ–è§£é‡Šè¯´æ˜

æ³¨æ„äº‹é¡¹ï¼š
- ä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆä¸€ä¸ªè¿‡æ¸¡é¡µ("transition")
- ä¸ºç« èŠ‚ä¸‹çš„æ¯ä¸ªèŠ‚ç”Ÿæˆä¸€ä¸ªå†…å®¹é¡µ("content")
- æ¯ä¸ªtextçš„å†…å®¹å¯ä»¥å°½é‡ä¸°å¯Œï¼Œä½†æ˜¯ä¸åº”è¯¥è¶…è¿‡100å­—

ç¤ºä¾‹æ ¼å¼ï¼ˆæ³¨æ„æ¯ä¸ª JSON å ä¸€è¡Œï¼‰ï¼š

{{"type": "transition", "data": {{ "title": "æ¥å£å®šä¹‰", "text": "å¼€å§‹ä»‹ç»æ¥å£çš„åŸºæœ¬å«ä¹‰" }}}}

{{"type": "content", "data": {{ "title": "æ¥å£å®šä¹‰", "items": [ {{ "title": "åŸºæœ¬æ¦‚å¿µ", "text": "æ¥å£å®šä¹‰äº†ä¸€ç»„æ–¹æ³•çš„å¥‘çº¦æˆ–è§„èŒƒï¼Œä½†ä¸æä¾›å…·ä½“å®ç°ã€‚å®ƒå¥½æ¯”ä¸€ä¸ªâ€œè“å›¾â€ï¼Œè§„å®šäº†å®ç°å®ƒçš„ç±»å¿…é¡»å…·å¤‡å“ªäº›åŠŸèƒ½ã€‚" }}, {{ "title": "ä½œç”¨", "text": "æ¥å£çš„ä¸»è¦ä½œç”¨æ˜¯å®ç°å¤šæ€å’Œæ¾è€¦åˆã€‚å®ƒè®©ä¸åŒç±»å‹çš„å¯¹è±¡èƒ½ä»¥ç»Ÿä¸€çš„æ–¹å¼è¢«å¤„ç†ï¼Œæé«˜äº†ä»£ç çš„çµæ´»æ€§ã€å¯æ‰©å±•æ€§å’Œå¤ç”¨æ€§ã€‚é€šè¿‡æ¥å£ï¼Œç³»ç»Ÿå„éƒ¨åˆ†ä¹‹é—´çš„ä¾èµ–æ€§é™ä½ï¼Œæ›´æ˜“äºç»´æŠ¤å’Œå‡çº§ã€‚" }} ] }}}}

è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆç« èŠ‚å†…å®¹ï¼š

è¯­è¨€ï¼š{language}
ç« èŠ‚æ ‡é¢˜ï¼š{section_title}
ç« èŠ‚å†…å®¹ï¼š{section_content}
"""

section_content_prompt = PromptTemplate.from_template(section_content_template)



def build_outline_chain(model_name: str = None):
    """æ„å»ºPPTå¤§çº²ç”Ÿæˆé“¾"""
    if not settings.validate():
        raise HTTPException(status_code=500, detail="OpenAI API Key æœªé…ç½®")
    
    model_config = settings.get_model_config(model_name)
    llm = ChatOpenAI(
        temperature=model_config["temperature"],
        model=model_config["model"],
        openai_api_key=model_config["openai_api_key"],
        openai_api_base=model_config["openai_api_base"]
    )
    return outline_prompt | llm | StrOutputParser()


def build_cover_contents_chain(model_name: str = None):
    """æ„å»ºå°é¢é¡µå’Œç›®å½•é¡µç”Ÿæˆé“¾"""
    if not settings.validate():
        raise HTTPException(status_code=500, detail="OpenAI API Key æœªé…ç½®")
    
    model_config = settings.get_model_config(model_name)
    llm = ChatOpenAI(
        temperature=model_config["temperature"],
        model=model_config["model"],
        openai_api_key=model_config["openai_api_key"],
        openai_api_base=model_config["openai_api_base"]
    )
    return cover_contents_prompt | llm | StrOutputParser()


def build_section_content_chain(model_name: str = None):
    """æ„å»ºç« èŠ‚å†…å®¹ç”Ÿæˆé“¾"""
    if not settings.validate():
        raise HTTPException(status_code=500, detail="OpenAI API Key æœªé…ç½®")
    
    model_config = settings.get_model_config(model_name)
    llm = ChatOpenAI(
        temperature=model_config["temperature"],
        model=model_config["model"],
        openai_api_key=model_config["openai_api_key"],
        openai_api_base=model_config["openai_api_base"]
    )
    return section_content_prompt | llm | StrOutputParser()




def parse_outline(content: str) -> dict:
    """è§£æå¤§çº²å†…å®¹ï¼Œæå–æ ‡é¢˜å’Œç« èŠ‚ä¿¡æ¯"""
    lines = content.strip().split('\n')
    result = {
        'title': '',
        'chapters': []
    }
    
    current_chapter = None
    current_section = None
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        if line.startswith('# '):  # PPTæ ‡é¢˜
            result['title'] = line[2:].strip()
        elif line.startswith('## '):  # ç« èŠ‚æ ‡é¢˜
            if current_chapter:
                result['chapters'].append(current_chapter)
            current_chapter = {
                'title': line[3:].strip(),
                'sections': []
            }
            current_section = None
        elif line.startswith('### '):  # èŠ‚æ ‡é¢˜
            if current_chapter:
                current_section = {
                    'title': line[4:].strip(),
                    'items': []
                }
                current_chapter['sections'].append(current_section)
        elif line.startswith('- '):  # å†…å®¹é¡¹
            if current_section:
                current_section['items'].append(line[2:].strip())
    
    # æ·»åŠ æœ€åä¸€ä¸ªç« èŠ‚
    if current_chapter:
        result['chapters'].append(current_chapter)
    
    return result


# è¯·æ±‚æ¨¡å‹å®šä¹‰
class PPTOutlineRequest(BaseModel):
    model: str = Field('gpt-4o-mini', description="ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼Œä¾‹å¦‚ gpt-4o æˆ– gpt-4o-mini")
    language: str = Field(..., description="ç”Ÿæˆå†…å®¹çš„è¯­è¨€ï¼Œä¾‹å¦‚ ä¸­æ–‡ã€English")
    content: str = Field(..., max_length=50, description="ç”Ÿæˆçš„è¦æ±‚ï¼Œä¸è¶…è¿‡50å­—")
    stream: bool = True


class PPTContentRequest(BaseModel):
    model: str = Field('gpt-4o-mini', description="ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼Œä¾‹å¦‚ gpt-4o æˆ– gpt-4o-mini")
    language: str = Field(..., description="ç”Ÿæˆå†…å®¹çš„è¯­è¨€ï¼Œä¾‹å¦‚ ä¸­æ–‡ã€English")
    content: str = Field(..., description="PPTå¤§çº²å†…å®¹")
    stream: bool = True


# è·¯ç”±å®ç°
@router.post("/tools/aippt_outline")
async def generate_ppt_outline_stream(request: PPTOutlineRequest):
    """ç”ŸæˆPPTå¤§çº²ï¼ˆæµå¼è¿”å›ï¼‰"""
    logger.info(f"ğŸ“ æ”¶åˆ°å¤§çº²ç”Ÿæˆè¯·æ±‚: æ¨¡å‹={request.model}, è¯­è¨€={request.language}, è¦æ±‚={request.content}")
    
    try:
        chain = build_outline_chain(request.model)
    except HTTPException as e:
        logger.error(f"æ„å»ºå¤§çº²ç”Ÿæˆé“¾å¤±è´¥: {e.detail}")
        raise e
    except Exception as e:
        logger.error(f"æ„å»ºå¤§çº²ç”Ÿæˆé“¾å¼‚å¸¸: {str(e)}")
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯")

    async def token_stream():
        try:
            logger.info("å¼€å§‹ç”ŸæˆPPTå¤§çº²...")
            async for chunk in chain.astream({
                "content": request.content,
                "language": request.language
            }):
                yield chunk
            logger.info("PPTå¤§çº²ç”Ÿæˆå®Œæˆ")
        except Exception as e:
            error_msg = f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"
            logger.error(error_msg)
            yield f"é”™è¯¯: {error_msg}"

    return StreamingResponse(token_stream(), media_type="text/event-stream")


@router.post("/tools/aippt")
async def generate_ppt_content_stream(request: PPTContentRequest):
    """ç”ŸæˆPPTå†…å®¹ï¼ˆåˆ†æ­¥éª¤æµå¼è¿”å›ï¼‰"""
    logger.info(f"ğŸ“„ æ”¶åˆ°å†…å®¹ç”Ÿæˆè¯·æ±‚: æ¨¡å‹={request.model}, è¯­è¨€={request.language}")
    logger.info(f"ğŸ“„ å¤§çº²å†…å®¹é•¿åº¦: {len(request.content)} å­—ç¬¦")
    
    # è§£æå¤§çº²
    try:
        outline_data = parse_outline(request.content)
        logger.info(f"ğŸ“„ è§£æå¤§çº²æˆåŠŸ: æ ‡é¢˜={outline_data['title']}, ç« èŠ‚æ•°={len(outline_data['chapters'])}")
    except Exception as e:
        logger.error(f"è§£æå¤§çº²å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=400, detail="å¤§çº²æ ¼å¼è§£æå¤±è´¥")
    
    # æ„å»ºç”Ÿæˆé“¾
    try:
        cover_contents_chain = build_cover_contents_chain(request.model)
        section_content_chain = build_section_content_chain(request.model)
    except HTTPException as e:
        logger.error(f"æ„å»ºç”Ÿæˆé“¾å¤±è´¥: {e.detail}")
        raise e
    except Exception as e:
        logger.error(f"æ„å»ºç”Ÿæˆé“¾å¼‚å¸¸: {str(e)}")
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯")
    
    async def structured_page_stream():
        page_count = 0
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆå°é¢é¡µå’Œç›®å½•é¡µ
            logger.info("ğŸ  å¼€å§‹ç”Ÿæˆå°é¢é¡µå’Œç›®å½•é¡µ...")
            buffer = ""
            async for chunk in cover_contents_chain.astream({
                "language": request.language,
                "content": request.content
            }):
                buffer += chunk
                # æ£€æŸ¥ç¼“å†²åŒºä¸­æ˜¯å¦åŒ…å«å®Œæ•´çš„é¡µé¢åˆ†éš”ç¬¦ "\n\n"
                while "\n\n" in buffer:
                    page_content, separator, rest_of_buffer = buffer.partition("\n\n")
                    if page_content.strip():
                        page_count += 1
                        logger.debug(f"ç”Ÿæˆç¬¬ {page_count} é¡µå†…å®¹ï¼ˆå°é¢/ç›®å½•ï¼‰")
                        yield page_content + separator
                    buffer = rest_of_buffer
            
            # å¤„ç†å‰©ä½™å†…å®¹
            if buffer.strip():
                page_count += 1
                logger.debug(f"ç”Ÿæˆç¬¬ {page_count} é¡µå†…å®¹ï¼ˆå°é¢/ç›®å½•æœ€åä¸€é¡µï¼‰")
                yield buffer + "\n\n"
            
            # ç¬¬äºŒæ­¥ï¼šä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆè¿‡æ¸¡é¡µå’Œå†…å®¹é¡µ
            for chapter_idx, chapter in enumerate(outline_data['chapters']):
                logger.info(f"ğŸ“– å¼€å§‹ç”Ÿæˆç¬¬ {chapter_idx + 1} ç« : {chapter['title']}")
                
                # å‡†å¤‡ç« èŠ‚å†…å®¹å­—ç¬¦ä¸²
                section_content = f"## {chapter['title']}\n"
                for section in chapter['sections']:
                    section_content += f"### {section['title']}\n"
                    for item in section['items']:
                        section_content += f"- {item}\n"
                
                buffer = ""
                async for chunk in section_content_chain.astream({
                    "language": request.language,
                    "section_title": chapter['title'],
                    "section_content": section_content
                }):
                    buffer += chunk
                    # æ£€æŸ¥ç¼“å†²åŒºä¸­æ˜¯å¦åŒ…å«å®Œæ•´çš„é¡µé¢åˆ†éš”ç¬¦ "\n\n"
                    while "\n\n" in buffer:
                        page_content, separator, rest_of_buffer = buffer.partition("\n\n")
                        if page_content.strip():
                            page_count += 1
                            logger.debug(f"ç”Ÿæˆç¬¬ {page_count} é¡µå†…å®¹ï¼ˆç¬¬{chapter_idx + 1}ç« ï¼‰")
                            yield page_content + separator
                        buffer = rest_of_buffer
                
                # å¤„ç†å‰©ä½™å†…å®¹
                if buffer.strip():
                    page_count += 1
                    logger.debug(f"ç”Ÿæˆç¬¬ {page_count} é¡µå†…å®¹ï¼ˆç¬¬{chapter_idx + 1}ç« æœ€åä¸€é¡µï¼‰")
                    yield buffer + "\n\n"
            
            # ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆç»“æŸé¡µ
            logger.info("ğŸ¬ å¼€å§‹ç”Ÿæˆç»“æŸé¡µ...")
            page_count += 1
            logger.debug(f"ç”Ÿæˆç¬¬ {page_count} é¡µå†…å®¹ï¼ˆç»“æŸé¡µï¼‰")
            yield '{"type": "end"}'
            
            logger.info(f"PPTå†…å®¹ç”Ÿæˆå®Œæˆï¼Œæ€»å…±ç”Ÿæˆ {page_count} é¡µ")
            
        except Exception as e:
            error_msg = f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"
            logger.error(error_msg)
            yield f'{{"error": "{error_msg}"}}'

    return StreamingResponse(structured_page_stream(), media_type="text/event-stream")


# æ·»åŠ å¥åº·æ£€æŸ¥ç«¯ç‚¹
@router.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {"status": "healthy", "message": "PPTist AI Backend is running"}


# æ·»åŠ JSONæ–‡ä»¶è¯»å–ç«¯ç‚¹
@router.get("/data/{filename}.json")
async def get_json_file(filename: str):
    """è¯»å–templateç›®å½•ä¸‹çš„JSONæ–‡ä»¶"""
    try:
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        file_path = os.path.join("template", f"{filename}.json")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(file_path):
            logger.warning(f"ğŸ“ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            raise HTTPException(status_code=404, detail=f"æ–‡ä»¶ {filename}.json ä¸å­˜åœ¨")
        
        # è¯»å–JSONæ–‡ä»¶
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        logger.info(f"ğŸ“„ æˆåŠŸè¯»å–æ–‡ä»¶: {filename}.json")
        return data
        
    except json.JSONDecodeError as e:
        logger.error(f"ğŸš« JSONæ ¼å¼é”™è¯¯: {filename}.json - {str(e)}")
        raise HTTPException(status_code=400, detail=f"æ–‡ä»¶ {filename}.json æ ¼å¼é”™è¯¯")
    except Exception as e:
        logger.error(f"ğŸš« è¯»å–æ–‡ä»¶å¤±è´¥: {filename}.json - {str(e)}")
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯")


# æ³¨å†Œè·¯ç”±
app.include_router(router)


# æ ¹è·¯å¾„
@app.get("/")
async def root():
    return {
        "message": "Welcome to PPTist AI Backend",
        "version": "0.1.0",
        "endpoints": {
            "outline": "/tools/aippt_outline",
            "content": "/tools/aippt",
            "health": "/health",
            "data": "/data/{filename}.json",
            "docs": "/docs"
        }
    }


if __name__ == "__main__":
    import uvicorn
    
    if not settings.validate():
        logger.error("âŒ å¯åŠ¨å¤±è´¥: OpenAI API Key æœªé…ç½®æˆ–æ— æ•ˆ")
        logger.error("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡æˆ–åˆ›å»º .env æ–‡ä»¶")
        logger.error("å¯ä»¥å¤åˆ¶ .env.example ä¸º .env å¹¶ä¿®æ”¹å…¶ä¸­çš„ API Key")
        exit(1)
    
    logger.info(f"ğŸš€ å¯åŠ¨ PPTist AI Backend...")
    logger.info(f"ğŸ“¡ æœåŠ¡å™¨åœ°å€: http://{settings.host}:{settings.port}")
    logger.info(f"ğŸ“š API æ–‡æ¡£: http://{settings.host}:{settings.port}/docs")
    
    try:
        uvicorn.run(
            "main:app",  # ä½¿ç”¨å­—ç¬¦ä¸²å¯¼å…¥è·¯å¾„ä»¥æ”¯æŒ reload åŠŸèƒ½
            host=settings.host,
            port=settings.port,
            reload=settings.debug
        )
    except Exception as e:
        logger.error(f"âŒ å¯åŠ¨å¤±è´¥: {str(e)}")
        logger.error("è¯·æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨æˆ–å…¶ä»–å¯åŠ¨é—®é¢˜")
        raise
